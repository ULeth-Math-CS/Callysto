{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from collections import namedtuple\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the urls that we need\n",
    "BASE_URL = \"http://climate.weather.gc.ca\"\n",
    "SEARCH_URL = \"http://climate.weather.gc.ca/historical_data/search_historic_data_e.html\"\n",
    "DAILY_DATA_URL = \"http://climate.weather.gc.ca/climate_data/daily_data_e.html\"\n",
    "SEARCH_STATIONS_URL = \"http://climate.weather.gc.ca/historical_data/search_historic_data_stations_e.html\"\n",
    "ALBERTA_STATIONS_URL = \"http://climate.weather.gc.ca/historical_data/search_historic_data_stations_e.html?searchType=stnProv&timeframe=1&lstProvince=AB&optLimit=yearRange&StartYear=1840&EndYear=2018&Year=2018&Month=5&Day=8&selRowPerPage=100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function that iterates through all the pages starting from\n",
    "#     a given url, and performs a given function on each one, storing\n",
    "#     the result of each function to a list.\n",
    "#\n",
    "# start_page can be the url of any page you wish to start on\n",
    "# func must be a function that operates on an entire page accepting\n",
    "#     a string of the entire page as its argument\n",
    "def all_pages(start_page, func):\n",
    "    list_of_info = []\n",
    "    current_page = start_page\n",
    "    flag = True\n",
    "    iteration = 1\n",
    "\n",
    "    \n",
    "    while(flag):\n",
    "        try:\n",
    "            #print(iteration)\n",
    "            #iteration += 1\n",
    "            #print(current_page)\n",
    "            \n",
    "            # Grab page contents and apply the function\n",
    "            content = requests.get(current_page).content\n",
    "            list_of_info.append(func(content))\n",
    "            \n",
    "            # Parse page then find the page links\n",
    "            soup = bs(content, 'lxml')\n",
    "            div = soup.findAll(\"div\", {\"class\": \"pull-left text-left\"})[-1]\n",
    "            \n",
    "            # Find the current page number\n",
    "            current_num = div.find(\"li\", {\"class\": \"active\"}).a.string\n",
    "            print(\"Page: \" + current_num)\n",
    "\n",
    "            # Find the next url to the next page\n",
    "            next_page = None\n",
    "            children = div.ul.find_all(\"li\")\n",
    "            for count, child in enumerate(children):\n",
    "                try:\n",
    "                    if child.attrs[\"class\"][0] == \"active\":\n",
    "                        next_page = children[count+1].a[\"href\"]\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            \n",
    "            # If the next_page was not found try finding the \"next\" link\n",
    "            if not next_page:\n",
    "                next_page = div.find(\"a\", {\"rel\": \"next\"})\n",
    "                # If on last page there is no next, so end\n",
    "                if not next_page:\n",
    "                    flag = False          \n",
    "\n",
    "            # The next_page becomes the current_page\n",
    "            current_page = BASE_URL + next_page\n",
    "            #if iteration == 10:\n",
    "            #    break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "    return list_of_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make library\n",
    "class date_range:\n",
    "    def __init__(self, string=None):\n",
    "        if string is None:\n",
    "            self.start_date_string = None\n",
    "            self.end_date_string = None\n",
    "            self.start_year = None      \n",
    "            self.start_month = None\n",
    "            self.start_day = None            \n",
    "            self.end_year = None\n",
    "            self.end_month = None\n",
    "            self.end_day = None\n",
    "        else:\n",
    "            self.parse_string(string)\n",
    "        \n",
    "    def parse_string(self, string):\n",
    "        split_range = string.split('|')\n",
    "        self.start_date_string = split_range[0]\n",
    "        self.end_date_string = split_range[1]\n",
    "        \n",
    "        split_start = split_range[0].split('-')\n",
    "        split_end = split_range[1].split('-')\n",
    "        \n",
    "        self.set_start_date(split_start[0], split_start[1], split_start[2])\n",
    "        self.set_end_date(split_end[0], split_end[1], split_end[2])\n",
    "                \n",
    "    def set_date_string(self, start, end):\n",
    "        self.start_date_string = start\n",
    "        self.end_date_string = end\n",
    "        \n",
    "    def set_start_date(self, year, month, day):\n",
    "        self.start_year = int(year)\n",
    "        self.start_month = int(month)\n",
    "        self.start_day = int(day)\n",
    "        \n",
    "    def set_end_date(self, year, month, day):\n",
    "        self.end_year = int(year)\n",
    "        self.end_month = int(month)\n",
    "        self.end_day = int(day)\n",
    "        \n",
    "    def get_start_date(self):\n",
    "        if (self.start_date_string is None and \n",
    "            (self.start_year is None or\n",
    "             self.start_month is None or\n",
    "             self.start_day is None)):\n",
    "            return None\n",
    "        \n",
    "        if self.start_year is None:\n",
    "            self.start_year = int(self.start_date_string.split('-')[0])\n",
    "        if self.start_month is None:\n",
    "            self.start_month = int(self.start_date_string.split('-')[1])\n",
    "        if self.start_day is None:\n",
    "            self.start_date = int(self.start_date_string.split('-')[2])\n",
    "            \n",
    "        return (self.start_year, self.start_month, self.start_day)\n",
    "    \n",
    "    def get_end_date(self):\n",
    "        if (self.end_date_string is None and \n",
    "            (self.end_year is None or\n",
    "             self.end_month is None or\n",
    "             self.end_day is None)):\n",
    "            return None\n",
    "        \n",
    "        if self.end_year is None:\n",
    "            self.end_year = int(self.end_date_string.split('-')[0])\n",
    "        if self.end_month is None:\n",
    "            self.end_month = int(self.end_date_string.split('-')[1])\n",
    "        if self.end_day is None:\n",
    "            self.end_date = int(self.end_date_string.split('-')[2])\n",
    "            \n",
    "        return (self.end_year, self.end_month, self.end_day)        \n",
    "     \n",
    "    def get_start_date_string(self):\n",
    "        if (self.start_date_string is None and\n",
    "            (self.start_year is None or\n",
    "             self.start_month is None or\n",
    "             self.start_day is None)):\n",
    "            return None\n",
    "        \n",
    "        return \"%i-%02d-%02d\" % (self.start_year, self.start_month,\n",
    "                                 self.start_day)                                \n",
    "    \n",
    "    def get_end_date_string(self):\n",
    "        if (self.end_date_string is None and\n",
    "            (self.end_date_year is None or\n",
    "             self.end_date_month is None or\n",
    "             self.end_date_day is None)):\n",
    "            return None\n",
    "        \n",
    "        return \"%i-%02d-%02d\" % (self.end_year, self.end_month,\n",
    "                                 self.end_day)\n",
    "    \n",
    "    # TODO implment\n",
    "    def is_leap_year(self, year):\n",
    "        return False\n",
    "    \n",
    "    def list_days(self, year, month):\n",
    "        if month == 2 and is_leap_year:\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def list_months(self, year):\n",
    "        if int(year) == self.start_year: \n",
    "            return range(self.start_month, 13)\n",
    "        elif int(year) == self.end_year:\n",
    "            return range(1, self.end_month)\n",
    "        else:\n",
    "            return range(1, 13)\n",
    "    \n",
    "    def list_years(self):\n",
    "        return range(self.start_year, self.end_year+1)\n",
    "\n",
    "    \n",
    "END_OF_MONTH = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class url_obj:\n",
    "    def __init__(self, url, payload=None, rng=None):\n",
    "        self.url = url\n",
    "        self.payload = payload\n",
    "        self.range = rng\n",
    "        self.page = None\n",
    "        \n",
    "    def get(self):\n",
    "        self.page = requests.get(self.url, params=self.payload)\n",
    "        \n",
    "    def grab_data(self, func):\n",
    "        return func(self.page)\n",
    "    \n",
    "    def list_days(self, year, month):\n",
    "        pass\n",
    "    \n",
    "    def list_months(self, year):\n",
    "        pass\n",
    "    \n",
    "    def list_years(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class station(object):\n",
    "    __slots__ = ('name', 'prov', 'lat', 'lon', 'elevation', \n",
    "                'station_id', 'start_date', 'end_date', \n",
    "                'climate_id', 'wmo_id', 'tc_id')\n",
    "    def __init__(self):\n",
    "        self.name = ''\n",
    "        self.prov = ''\n",
    "        self.lat = 0.0\n",
    "        self.lon = 0.0\n",
    "        self.elevation = ''\n",
    "        self.station_id = ''\n",
    "        self.start_date = ''\n",
    "        self.end_date = ''\n",
    "        self.climate_id = ''\n",
    "        self.wmo_id = ''\n",
    "        self.tc_id = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_fourm(content, year, month, day):\n",
    "    fourm = {}\n",
    "    inputs = content.find_all(\"input\", {\"type\": \"hidden\"})\n",
    "    \n",
    "    for element in inputs:\n",
    "        fourm[str(element.attrs[\"name\"])] = element.attrs[\"value\"]        \n",
    "    fourm[\"timeframe\"] = \"2\"\n",
    "    fourm[\"year\"] = str(year)\n",
    "    fourm[\"month\"] = str(month)\n",
    "    fourm[\"day\"] = str(day)\n",
    "    return fourm\n",
    "\n",
    "# Helper functions to grab the range of dates that can be used, from a\n",
    "#     Beuatiful Soup object\n",
    "def get_dates(content):\n",
    "    found = content.find(\"input\", {\"type\": \"hidden\", \"name\": \"dlyRange\"})\n",
    "    if not found:\n",
    "        print(\"wrong\")\n",
    "    dates = found.attrs[\"value\"]\n",
    "    \n",
    "    # TODO Fix this\n",
    "    if dates == '|':\n",
    "        dates = content.find(\"input\", {\"type\": \"hidden\", \"name\": \"hlyRange\"}).attrs[\"value\"]\n",
    "    if dates == '|':\n",
    "        dates = content.find(\"input\", {\"type\": \"hidden\", \"name\": \"mlyRange\"}).attrs[\"value\"]\n",
    "    rng = date_range(dates)\n",
    "        \n",
    "    return rng\n",
    "\n",
    "def get_station_info(page_obj):\n",
    "    s = station()\n",
    "\n",
    "    url = page_obj.url\n",
    "    url = url.split(\"&\")\n",
    "    for part in url:\n",
    "        if part[:10] == \"StationID=\":\n",
    "            s.station_id = part[10:]\n",
    "            break\n",
    "\n",
    "    page = page_obj.content\n",
    "    soup = bs(page, 'lxml')\n",
    "    name_content = soup.find(\"p\", {\"class\": \"text-center table-header pdng-md mrgn-bttm-0\"}).contents\n",
    "    s.name = name_content[0]\n",
    "    s.prov = name_content[2]\n",
    "    \n",
    "    print(s.name)\n",
    "    \n",
    "    lat = soup.find(\"div\", {\"aria-labelledby\": \"latitude\"}).contents\n",
    "    deg = lat[0]\n",
    "    minute = lat[2]\n",
    "    second = lat[4]\n",
    "    s.lat = float(deg) + float(minute)/60 + float(second)/3600\n",
    "\n",
    "    lon = soup.find(\"div\", {\"aria-labelledby\": \"longitude\"}).contents\n",
    "    deg = lon[0]\n",
    "    minute = lon[2]\n",
    "    second = lon[4]\n",
    "    s.lon = 360-float(deg) + float(minute)/60 + float(second)/3600 \n",
    "    s.elevation = soup.find(\"div\", {\"aria-labelledby\": \"elevation\"}).contents[0] \n",
    "    \n",
    "    climate_id = soup.find(\"div\", {\"aria-labelledby\": \"climateid\"}).contents\n",
    "    if not climate_id:\n",
    "        s.climate_id = None\n",
    "    else:\n",
    "        s.climate_id = climate_id[0]\n",
    "    \n",
    "    wmo_id = soup.find(\"div\", {\"aria-labelledby\": \"wmoid\"}).contents\n",
    "    if not wmo_id:\n",
    "        s.wmo_id = None\n",
    "    else:\n",
    "        s.wmo_id = wmo_id[0]\n",
    "        \n",
    "    tc_id = soup.find(\"div\", {\"aria-labelledby\": \"tcid\"}).contents\n",
    "    if not tc_id:\n",
    "        s.tc_id = None\n",
    "    else:\n",
    "        s.tc_id = tc_id[0]\n",
    "\n",
    "    return s\n",
    "\n",
    "def all_stations(page, func=get_station_info):\n",
    "    soup = bs(page, 'lxml')\n",
    "    \n",
    "    # A list of all the stations on the page\n",
    "    results = soup.find_all(\"form\", {\"id\": re.compile(\"stnRequest[0-9]+-sm\")})\n",
    "    print('%i of results on this page\\n' % len(results))\n",
    "    list_of_stations = []\n",
    "    for element in results:\n",
    "        dates = get_dates(element)\n",
    "        \n",
    "        fourm = fill_fourm(element, *dates.get_end_date())\n",
    "        page_obj = requests.get(DAILY_DATA_URL, params=fourm)\n",
    "        s = func(page_obj)\n",
    "        s.start_date = dates.get_start_date_string()\n",
    "        list_of_stations.append(s)\n",
    "    return list_of_stations\n",
    "    \n",
    "    \n",
    "def search_station(name):\n",
    "    payload = {\n",
    "        \"searchType\": \"stnName\",\n",
    "        \"timeframe\": \"1\",\n",
    "        \"txtStationName\": name,\n",
    "        \"optLimit\": \"yearRange\",\n",
    "        \"StartYear\": \"1840\",\n",
    "        \"EndYear\": \"2018\",\n",
    "        \"Year\": \"2018\",\n",
    "        \"Month\": \"4\",\n",
    "        \"Day\": \"28\",\n",
    "        \"selRowPerPage\": \"100\",\n",
    "    }\n",
    "    content = requests.get(SEARCH_STATIONS_URL, params=payload).content\n",
    "    get_stations(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 of results on this page\n",
      "\n",
      "(AE) BOW SUMMIT\n",
      "ABEE AGDM\n",
      "ACADIA VALLEY\n",
      "ACADIA VALLEY\n",
      "ACADIA VALLEY CDA EPF\n",
      "ACADIA VALLEY EXP ST\n",
      "ACADIA VALLEY MACTAVISH\n",
      "ACADIA VALLEY VANDYNE\n",
      "ACME CDA EPF\n",
      "ADAIR LO\n",
      "ADAMS CREEK LO\n",
      "ADEN\n",
      "AIRDRIE\n",
      "AKAMINA PASS\n",
      "ALBERT HALL AGCM\n",
      "ALDER FLATS LO\n",
      "ALGAR LO\n",
      "ALIX\n",
      "ALIX\n",
      "ALLIANCE\n",
      "ALLIANCE AGCM\n",
      "ALLIANCE GREENVIEW\n",
      "ALLIANCE SOUTH\n",
      "ALSASK\n",
      "ALTAWAN\n",
      "AMBER LO\n",
      "AMISK\n",
      "ANDREW\n",
      "ANDREW AGDM\n",
      "ANSELL LO\n",
      "ANSELMO\n",
      "ANTHRACITE\n",
      "ANTLER HILL\n",
      "ANZAC\n",
      "ANZAC\n",
      "ARDENVILLE\n",
      "ARMADA EXP ST\n",
      "ARMENA\n",
      "ARNESON\n",
      "ARROWWOOD\n",
      "ASSUMPTION\n",
      "ASSUMPTION\n",
      "ATHABASCA\n",
      "ATHABASCA 1\n",
      "ATHABASCA 2\n",
      "ATHABASCA 3\n",
      "ATHABASCA AGCM\n",
      "ATHABASCA EXP ST\n",
      "ATHABASCA LANDING\n",
      "ATHABASCA LO\n",
      "ATIKAMEG\n",
      "ATLEE\n",
      "ATLEE AGCM\n",
      "ATMORE\n",
      "ATMORE AGDM\n",
      "AURORA LO\n",
      "AZURE\n",
      "BAIRD LAKE\n",
      "BALD MOUNTAIN LO\n",
      "BALDY LO\n",
      "BALLATER\n",
      "BALLATER AGCM\n",
      "BALM\n",
      "BANANA BELT\n",
      "BANFF\n",
      "BANFF (AUT)\n",
      "BANFF CR10\n",
      "BANFF CS\n",
      "BANFF SPRINGS\n",
      "BAPTISTE LAKE\n",
      "BARNWELL AGDM\n",
      "BARONS AGCM\n",
      "BARONS EXP ST\n",
      "BARONS EXP ST 2\n",
      "BARRHEAD\n",
      "BARRHEAD CS\n",
      "BARRIER LAKE\n",
      "BASELINE LO\n",
      "BASHAW\n",
      "BASHAW\n",
      "BASNETT\n",
      "BASSANO AGCM\n",
      "BASSANO DAM\n",
      "BASSANO GEM\n",
      "BASSET LO\n",
      "BATTLE CREEK LO\n",
      "BATTLE HEADWATERS\n",
      "BATTLE RIVER LO\n",
      "BEARBERRY\n",
      "BEAUVAIS PARK\n",
      "BEAVER HILLS WEST\n",
      "BEAVER LAKE RS\n",
      "BEAVER MINES\n",
      "BEAVER MINES\n",
      "BEAVERLODGE CDA\n",
      "BEAVERLODGE CDA\n",
      "BEAVERLODGE RCS\n",
      "BEAVERLODGE REDLOW\n",
      "BEISEKER AGCM\n",
      "BEISEKER VILLAGE\n",
      "BELLIS\n",
      "Page: 1\n",
      "101 of results on this page\n",
      "\n",
      "BELLIS\n",
      "BELLIS\n",
      "BELLSHILL AGCM\n",
      "BENALTO\n",
      "BERLAND LO\n",
      "BERNY\n",
      "BERRY CREEK\n",
      "BERWYN\n",
      "BERWYN CDA\n",
      "BIG COULEE\n",
      "BIG STONE\n",
      "BIG STONE LOCKHART\n",
      "BIG VALLEY\n",
      "BIG VALLEY AGCM\n",
      "BIG VALLEY WEST\n",
      "BIGHORN DAM\n",
      "BINDLOSS\n",
      "BINDLOSS EAST\n",
      "BINDLOSS EXP ST\n",
      "BIRCH LAKE\n",
      "BIRCH MOUNTAIN LO\n",
      "BIRCH MOUNTAIN TOWER\n",
      "BISMARK\n",
      "BISON LO\n",
      "BISTCHO LAKE (F5)\n",
      "BITTERN LAKE\n",
      "BITUMONT LO\n",
      "BLACK DIAMOND\n",
      "BLACKIE\n",
      "BLACKIE 2W\n",
      "BLACKIE AGCM\n",
      "BLACKIE NORTH\n",
      "BLACKIE NW\n",
      "BLACKSTONE LO\n",
      "BLAIRMORE HQTS RS\n",
      "BLINDMAN\n",
      "BLOOD INDIAN CREEK\n",
      "BLOOD TRIBE AGDM\n",
      "BLUEBERRY CREEK\n",
      "BLUEBERRY MTN CDA EPF\n",
      "BLUEHILL LO\n",
      "BLUFFTON\n",
      "BOB CREEK\n",
      "BODO AGDM\n",
      "BONNIE VIEW\n",
      "BONNYVILLE EXP ST\n",
      "BOVINE CREEK AFS\n",
      "BOW ISLAND\n",
      "BOW ISLAND\n",
      "BOW ISLAND EXP ST\n",
      "BOW ISLAND IRRIGATION AGDM\n",
      "BOW ISLAND RIVERS DEV\n",
      "BOW SUMMIT (PC)\n",
      "BOW VALLEY\n",
      "BOW VALLEY PROV PARK\n",
      "BOWDEN\n",
      "BOWNESS\n",
      "BOYLE\n",
      "BRAGG CREEK WEST\n",
      "BRANT\n",
      "BRAZEAU LO\n",
      "BREMNER\n",
      "BRETON\n",
      "BRETON PLOTS\n",
      "BRETON TOWN\n",
      "BRIARFIELD\n",
      "BRIGHTVIEW\n",
      "BRIGHTWOOD\n",
      "BROCKET AGDM\n",
      "BROOKS\n",
      "BROOKS\n",
      "BROOKS 1\n",
      "BROOKS AHRC\n",
      "BROOKS NORTH\n",
      "BROOKS ONE TREE\n",
      "BROWNFIELD\n",
      "BROWNVALE AGCM\n",
      "BRUDERHEIM\n",
      "BRULE BLACK CAT\n",
      "BUCK MOUNTAIN\n",
      "BUCK MOUNTAIN\n",
      "BUCKTON LO\n",
      "BUFFALO\n",
      "BUFFALO AGCM\n",
      "BUFFALO HEAD PRAIRIE\n",
      "BUFFALO LO\n",
      "BULL SPRINGS AGCM\n",
      "BULLHORN COULEE RESERVOIR\n",
      "BULLHORN HEADWATERS\n",
      "BULLPOUND CREEK\n",
      "BURNS CREEK\n",
      "BURNSTICK LO\n",
      "BURNT TIMBER LO\n",
      "BUSBY\n",
      "BUSBY AGCM\n",
      "CABIN LAKE AGCM\n",
      "CADOGAN\n",
      "CADOGAN\n",
      "CADOGAN AGCM\n",
      "CADOTTE LO\n",
      "CALDWELL\n",
      "Page: 2\n",
      "101 of results on this page\n",
      "\n",
      "CALDWELL\n",
      "CALENDULA SIBBALD\n",
      "CALGARY BEARSPAW\n",
      "CALGARY BELLEVIEW\n",
      "CALGARY ELBOW VIEW\n",
      "CALGARY GLENMORE DAM\n",
      "CALGARY INT'L A\n",
      "CALGARY INT'L CS\n",
      "CALGARY INTL A\n",
      "CALGARY MARLBOROUGH\n",
      "CALGARY MIDNAPORE\n",
      "CALGARY NOSE HILL\n",
      "CALGARY POPLAR GARDENS\n",
      "CALGARY ROSSCARROCK\n",
      "CALGARY SIMONS VALLEY\n",
      "CALGARY SPRINGBANK\n",
      "CALGARY SPRINGBANK\n",
      "CALGARY SPRINGBANK A\n",
      "CALGARY SPRINGBANK A\n",
      "CALLING LAKE RS\n",
      "CALMAR\n",
      "CALMAR TOWNSITE\n",
      "CALMAR WEST\n",
      "CAMBRIA LO\n",
      "CAMERON COULEE\n",
      "CAMERON FALLS\n",
      "CAMP WAINWRIGHT AIRFIELD 21\n",
      "CAMPSIE\n",
      "CAMPSIE AUTO\n",
      "CAMROSE\n",
      "CAMROSE\n",
      "CAMROSE 2\n",
      "CANMORE\n",
      "CAPPON\n",
      "CAPPON SOUTH\n",
      "CARBON\n",
      "CARBONDALE LO\n",
      "CARDSTON\n",
      "CARDSTON\n",
      "CARDSTON\n",
      "CARDSTON EXP ST\n",
      "CARIBOU MTN LO\n",
      "CARIBOU MTN LO\n",
      "CARLSON TOWER\n",
      "CARLSON'S LANDING LO\n",
      "CARMANGAY\n",
      "CARMANGAY EXP ST\n",
      "CARMANGAY EXP ST 2\n",
      "CARMANGAY EXP ST 3\n",
      "CARMANGAY PLAINFIELD\n",
      "CARMANGAY VILLAGE\n",
      "CARNWOOD\n",
      "CARROT CREEK\n",
      "CARROT CREEK\n",
      "CARROT CREEK LO\n",
      "CARSTAIRS WEST\n",
      "CARWAY\n",
      "CARWAY\n",
      "CASTLE\n",
      "CASTLE MOUNTAIN VILLAGE\n",
      "CASTOR\n",
      "CASTOR\n",
      "CAYLEY\n",
      "CEREAL\n",
      "CEREAL AGCM\n",
      "CESSFORD\n",
      "CHAILEY\n",
      "CHAIN LAKES RS\n",
      "CHAMPION AGDM\n",
      "CHAPEL ROCK\n",
      "CHAUVIN\n",
      "CHAUVIN EXP ST\n",
      "CHEDDERVILLE CDA EPF\n",
      "CHERRY MOUNTAIN TOWER\n",
      "CHESTERMERE LAKE SOUTH\n",
      "CHIEF CUSTOMS\n",
      "CHINCHAGA LO\n",
      "CHIPEWYAN LAKES LO\n",
      "CHIPMAN\n",
      "CHISHOLM LO\n",
      "CHISHOLM MILLS\n",
      "CHRISTINA LAKE\n",
      "CHRISTINA LO\n",
      "CHUNGO LO\n",
      "CLARESHOLM\n",
      "CLARESHOLM EXP FARM\n",
      "CLARESHOLM EXP ST\n",
      "CLARESHOLM LAING\n",
      "CLARESHOLM LYNDON CREEK\n",
      "CLARESHOLM MEADOW CREEK\n",
      "CLARESHOLM NORTH\n",
      "CLARESHOLM TROUT CREEK\n",
      "CLARESHOLM WATERWORKS\n",
      "CLEAR HILLS AGCM\n",
      "CLEAR HILLS LO\n",
      "CLEARDALE\n",
      "CLEARDALE AGDM\n",
      "CLEARWATER\n",
      "CLINE LO\n",
      "CLINE LO\n",
      "COAL VALLEY\n",
      "Page: 3\n",
      "101 of results on this page\n",
      "\n",
      "COAL VALLEY\n",
      "COALCAMP CREEK\n",
      "COALDALE\n",
      "COALDALE EXP ST\n",
      "COALSPUR\n",
      "COCHRANE\n",
      "COCHRANE BIGHILL CREEK\n",
      "COCHRANE CATHCART\n",
      "COCHRANE VE6CQC\n",
      "CODESA LO\n",
      "COLD CREEK RS\n",
      "COLD LAKE A\n",
      "COLD LAKE SNOW\n",
      "COLEMAN\n",
      "COLEMAN RS\n",
      "COLINTON\n",
      "COLUMBIA ICEFIELD\n",
      "COMPEER\n",
      "COMPRESSION RIDGE\n",
      "CONKLIN\n",
      "CONKLIN LO\n",
      "CONNELLY CREEK\n",
      "CONSORT AGDM\n",
      "CONSORT CDA EPF\n",
      "CONSORT WADES\n",
      "CONTRACOSTA LAKE\n",
      "COOKING LAKE\n",
      "COP UPPER\n",
      "COPTON LO\n",
      "CORONATION\n",
      "CORONATION (AUT)\n",
      "CORONATION A\n",
      "CORONATION CLIMATE\n",
      "COUTTS\n",
      "COUTTS EXP ST\n",
      "COWLEY\n",
      "COWLEY A\n",
      "COWLEY CREEBANK RANCH\n",
      "COWLEY OLIN CREEK\n",
      "COWLEY TANNER\n",
      "COWLEY TODD CREEK\n",
      "COWPAR LO\n",
      "COX HILL\n",
      "CRAIGMYLE\n",
      "CRAIGMYLE AGCM\n",
      "CREMONA\n",
      "CRESTOMERE AGCM\n",
      "CROSS CONSERVATION AREA\n",
      "CROSS LAKE\n",
      "CROSS LAKE RS\n",
      "CROSSFIELD\n",
      "CROWE TOWER\n",
      "CROWSNEST\n",
      "CROWSNEST CREEK\n",
      "CUTHEAD LAKE\n",
      "CYNTHIA\n",
      "DAKOTA\n",
      "DAKOTA WEST\n",
      "DAPP\n",
      "DAPP AGDM\n",
      "DARWELL\n",
      "DAVID THOMPSON RESORT\n",
      "DAVIDSON LAKE TOWER\n",
      "DAYSLAND\n",
      "DE WINTON\n",
      "DEADWOOD\n",
      "DEADWOOD AGCM\n",
      "DEADWOOD EXP ST\n",
      "DEADWOOD LO\n",
      "DEADWOOD REINWOOD\n",
      "DEBOLT GOODWIN\n",
      "DEBOLT RS\n",
      "DEER MOUNTAIN LO\n",
      "DEL BONITA\n",
      "DEL BONITA\n",
      "DEL BONITA AGDM\n",
      "DEL BONITA EXP ST\n",
      "DELBURNE AGCM\n",
      "DELIA\n",
      "DEMMITT CDA EPF\n",
      "DEVONA\n",
      "DEWBERRY\n",
      "DEWBERRY AGCM\n",
      "DICKSON DAM\n",
      "DIDSBURY\n",
      "DIDSBURY ELKTON\n",
      "DODDS ROUND HILL\n",
      "DOG POUND\n",
      "DOGRIB CREEK\n",
      "DOIG LO\n",
      "DONALDA SOUTH\n",
      "DONNELLY\n",
      "DOUCETTE LO\n",
      "DOWLING LAKE\n",
      "DRAYTON VALLEY\n",
      "DRAYTON VALLEY\n",
      "DRUMHELLER\n",
      "DRUMHELLER ANDREW\n",
      "DRUMHELLER CITY\n",
      "DRUMHELLER EAST\n",
      "DRUMHELLER INSTITUTION\n",
      "Page: 4\n",
      "101 of results on this page\n",
      "\n",
      "DRUMHELLER INSTITUTION\n",
      "DUCHESS\n",
      "DUCKWORTH FARM\n",
      "DUNKIRK L3\n",
      "DUNVEGAN\n",
      "DUPRE AGCM\n",
      "EAGLE BUTTE\n",
      "EAGLE LAKE PARK\n",
      "EAGLE LO\n",
      "EAGLESHAM\n",
      "EAGLESHAM AGCM\n",
      "EAST BERRY CREEK\n",
      "ECKVILLE\n",
      "ECKVILLE SOUTH\n",
      "ECONOMY LO\n",
      "EDBERG\n",
      "EDGERTON AGCM\n",
      "EDMONTON\n",
      "EDMONTON AB RESEARCH PARK\n",
      "EDMONTON BLATCHFORD\n",
      "EDMONTON CALDER\n",
      "EDMONTON CITY CENTRE A\n",
      "EDMONTON CITY CENTRE AWOS\n",
      "EDMONTON CLOVERBAR\n",
      "EDMONTON CORONATION\n",
      "EDMONTON GARRISON\n",
      "EDMONTON INT'L A\n",
      "EDMONTON INTERNATIONAL CS\n",
      "EDMONTON INTL A\n",
      "EDMONTON LYNNWOOD\n",
      "EDMONTON NAMAO A\n",
      "EDMONTON NAMAO AWOS A\n",
      "EDMONTON PLEASANTVIEW\n",
      "EDMONTON SMITH WATER TREATMENT\n",
      "EDMONTON SOUTH CAMPUS\n",
      "EDMONTON STONY PLAIN\n",
      "EDMONTON STONY PLAIN CS\n",
      "EDMONTON TIEBEKE ESTATES\n",
      "EDMONTON VILLENEUVE A\n",
      "EDMONTON VILLENEUVE A\n",
      "EDMONTON WOODBEND\n",
      "EDRA LO\n",
      "EDSON\n",
      "EDSON\n",
      "EDSON\n",
      "EDSON A\n",
      "EDSON A\n",
      "EDSON AWOS A\n",
      "EDSON CLIMATE\n",
      "EGG ISLAND\n",
      "EISENHOWER JUNCTION\n",
      "ELBOW RS\n",
      "ELK ISLAND NAT PARK\n",
      "ELK ISLAND PARK\n",
      "ELK ISLAND SIDING\n",
      "ELK POINT\n",
      "ELK RIVER AFS\n",
      "ELK RIVER ER RS\n",
      "ELLERSLIE\n",
      "ELLS LO\n",
      "ELLSCOTT\n",
      "ELMWORTH\n",
      "ELMWORTH CDA EPF\n",
      "ELMWORTH CDA EPF\n",
      "ELNORA\n",
      "ELNORA SALEM\n",
      "EMBARRAS A\n",
      "EMPRESS\n",
      "EMPRESS DOT\n",
      "ENCHANT\n",
      "ENCHANT AGDM\n",
      "ENDIANG\n",
      "ENILDA LO\n",
      "ENILDA-BERG\n",
      "ENTRANCE\n",
      "ENTRANCE RS\n",
      "ENTWISTLE\n",
      "ESTHER\n",
      "ESTHER 1\n",
      "ESTHER PRATT\n",
      "ETA LAKE\n",
      "ETZIKOM AGCM\n",
      "EUREKA RIVER\n",
      "EVANS THOMAS\n",
      "EVANSBURG AGCM\n",
      "EVANSBURG CDA EPF\n",
      "EVANSBURG2 AGCM\n",
      "EVARTS\n",
      "EXCEL\n",
      "EXSHAW\n",
      "FABYAN\n",
      "FAIRVIEW\n",
      "FAIRVIEW 2\n",
      "FAIRVIEW AGDM\n",
      "FAIRVIEW FSA\n",
      "FAIRVIEW THREE FOX FARM\n",
      "FALHER\n",
      "FALLEN TIMBER\n",
      "FALLIS\n",
      "FALSE NICHOLAS\n",
      "FERINTOSH AGCM\n",
      "Page: 5\n",
      "101 of results on this page\n",
      "\n",
      "FERINTOSH AGCM\n",
      "FINCASTLE AGDM\n",
      "FINNEGAN\n",
      "FINNEGAN AGCM\n",
      "FISH CREEK\n",
      "FIVE LAKES\n",
      "FIVE MILE CREEK\n",
      "FLATTOP LO\n",
      "FLEET\n",
      "FLEET AGCM\n",
      "FLORANN\n",
      "FOGGY LO\n",
      "FONTAS LO\n",
      "FOOTNER LAKE HQ\n",
      "FOREMOST\n",
      "FOREMOST AGDM\n",
      "FOREMOST EAST\n",
      "FOREMOST EXP ST\n",
      "FORESTBURG\n",
      "FORESTBURG AGCM\n",
      "FORESTBURG PLANT SITE\n",
      "FORGET ME NOT LO\n",
      "FORGET ME NOT MOUNTAIN\n",
      "FORT ASSINIBOINE\n",
      "FORT ASSINIBOINE 2\n",
      "FORT ASSINIBOINE AGCM\n",
      "FORT ASSINIBOINE RS\n",
      "FORT ASSINIBOINE RS\n",
      "FORT CHIPEWYAN\n",
      "FORT CHIPEWYAN\n",
      "FORT CHIPEWYAN\n",
      "FORT CHIPEWYAN A\n",
      "FORT CHIPEWYAN AWOS A\n",
      "FORT CHIPEWYAN RCS\n",
      "FORT EDMONTON\n",
      "FORT KENT CDA EPF\n",
      "FORT MACKAY RS\n",
      "FORT MACLEOD\n",
      "FORT MACLEOD AGCM\n",
      "FORT MACLEOD EXP ST\n",
      "FORT MACLEOD EXP ST 2\n",
      "FORT MACLEOD NORTH\n",
      "FORT MACLEOD STAND OFF\n",
      "FORT MCMURRAY A\n",
      "FORT MCMURRAY A\n",
      "FORT MCMURRAY AWOS A\n",
      "FORT MCMURRAY CS\n",
      "FORT SASKATCHEWAN\n",
      "FORT VERMILION\n",
      "FORT VERMILION\n",
      "FORT VERMILION\n",
      "FORT VERMILION CDA\n",
      "FORT VERMILION RS\n",
      "FORTRESS MOUNTAIN\n",
      "FOX CREEK\n",
      "FOX CREEK JUNCTION\n",
      "FOX CREEK RS\n",
      "FREEMAN RIVER\n",
      "FRISCO\n",
      "FROG LAKE RS\n",
      "FT MCMURRAY\n",
      "FURMAN CLARESHOLM\n",
      "GADSBY\n",
      "GAINFORD\n",
      "GARDEN RIVER\n",
      "GARDEN RIVER\n",
      "GARDINER CREEK\n",
      "GEM\n",
      "GENESEE\n",
      "GHOST DIVERSION\n",
      "GHOST PINE CREEK\n",
      "GHOST RS\n",
      "GIBBONS\n",
      "GIFT LAKE LO\n",
      "GILT EDGE NORTH AGCM\n",
      "GLADSTONE AGCM\n",
      "GLASSFORD\n",
      "GLEICHEN\n",
      "GLEICHEN AGCM\n",
      "GLENDON\n",
      "GLENEVIS\n",
      "GLENEVIS AGCM\n",
      "GLENWOOD\n",
      "GLENWOODVILLE EXP ST\n",
      "GOAT'S EYE\n",
      "GOLDEN VALLEY\n",
      "GOODFARE CDA EPF\n",
      "GOODRIDGE RS\n",
      "GOOSE MOUNTAIN LO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOSEBERRY LAKE\n",
      "GOOSEBERRY LAKE AGCM\n",
      "GORDON LAKE LO\n",
      "GRANDE CACHE\n",
      "GRANDE CACHE AUTO\n",
      "GRANDE CACHE MILNER\n",
      "GRANDE CACHE RS\n",
      "GRANDE CACHE S.T.P.\n",
      "GRANDE LO\n",
      "GRANDE PRAIRIE\n",
      "GRANDE PRAIRIE A\n",
      "GRANDE PRAIRIE A\n",
      "Page: 6\n",
      "101 of results on this page\n",
      "\n",
      "GRANDE PRAIRIE A\n",
      "GRANDE PRAIRIE CR21X\n",
      "GRANUM JUMBO VALLEY\n",
      "GRASSY LAKE\n",
      "GRASSY LAKE\n",
      "GRASSY LAKE RIVERS DEV\n",
      "GRAVE FLATS LO\n",
      "GROSMONT\n",
      "GROTON\n",
      "GROUARD\n",
      "GROUARD\n",
      "GROUND ZERO AFS\n",
      "GROVEDALE RS\n",
      "GULL LAKE GOLF COURSE\n",
      "GUY\n",
      "GWYNNE\n",
      "HACKETT\n",
      "HAILSTONE BUTTE LO\n",
      "HALKIRK\n",
      "HALKIRK AGCM\n",
      "HAND HILLS AGCM\n",
      "HANNA\n",
      "HARDISTY\n",
      "HARMATTAN\n",
      "HASTINGS LAKE\n",
      "HAWK HILLS AGCM\n",
      "HAWK HILLS LO\n",
      "HAY CAMP TOWER\n",
      "HAY LAKES RS\n",
      "HAY RIVER RS\n",
      "HAYS\n",
      "HEART LAKE LO\n",
      "HEISLER 10S\n",
      "HELDAR\n",
      "HEMARUKA\n",
      "HEMARUKA AGCM\n"
     ]
    }
   ],
   "source": [
    "list_of_list_of_stations = all_pages(ALBERTA_STATIONS_URL, all_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 of results on this page\n",
      "\n",
      "<class 'bs4.element.ResultSet'>\n",
      "<__main__.date_range object at 0x7f25e89d1d30>\n",
      "<__main__.date_range object at 0x7f25e89d1d30>\n",
      "<__main__.date_range object at 0x7f25e89d1d30>\n"
     ]
    }
   ],
   "source": [
    "with open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 1\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Page: 8\n",
      "Page: 9\n",
      "Page: 10\n",
      "Page: 11\n",
      "Page: 12\n",
      "Page: 13\n",
      "Page: 14\n",
      "Page: 15\n",
      "Page: 16\n",
      "Page: 17\n",
      "Page: 18\n",
      "Page: 19\n",
      "Page: 20\n",
      "Page: 21\n",
      "Page: 22\n",
      "Page: 23\n",
      "Page: 24\n",
      "Page: 25\n",
      "Page: 26\n",
      "Page: 27\n",
      "Page: 28\n",
      "Page: 29\n",
      "Page: 30\n",
      "Page: 31\n",
      "Page: 32\n",
      "Page: 33\n",
      "Page: 34\n",
      "Page: 35\n",
      "Page: 36\n",
      "Page: 37\n",
      "Page: 38\n",
      "Page: 39\n",
      "Page: 40\n",
      "Page: 41\n",
      "Page: 42\n",
      "Page: 43\n",
      "Page: 44\n",
      "Page: 45\n",
      "Page: 46\n",
      "Page: 47\n",
      "Page: 48\n",
      "Page: 49\n",
      "Page: 50\n",
      "Page: 51\n",
      "Page: 52\n",
      "Page: 53\n",
      "Page: 54\n",
      "Page: 55\n",
      "Page: 56\n",
      "Page: 57\n",
      "Page: 58\n",
      "Page: 59\n",
      "Page: 60\n",
      "Page: 61\n",
      "Page: 62\n",
      "Page: 63\n",
      "Page: 64\n",
      "Page: 65\n",
      "Page: 66\n",
      "Page: 67\n",
      "Page: 68\n",
      "Page: 69\n",
      "Page: 70\n",
      "Page: 71\n",
      "Page: 72\n",
      "Page: 73\n",
      "Page: 74\n",
      "Page: 75\n",
      "Page: 76\n",
      "Page: 77\n",
      "Page: 78\n",
      "Page: 79\n",
      "Page: 80\n",
      "Page: 81\n",
      "Page: 82\n",
      "Page: 83\n",
      "Page: 84\n",
      "Page: 85\n",
      "Page: 86\n",
      "Page: 87\n",
      "Page: 88\n"
     ]
    }
   ],
   "source": [
    "def count_recent(data):\n",
    "    soup = bs(data, 'lxml')\n",
    "    # A list of all the stations on the page\n",
    "    results = soup.find_all(\"form\", {\"id\": re.compile(\"stnRequest[0-9]+-sm\")})\n",
    "    #print('%i of results on this page\\n' % len(results))\n",
    "    #print(type(results))\n",
    "    count = 0\n",
    "    for element in results:\n",
    "        if str(get_dates(element).get_end_date()[0]) == \"2018\":\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "result = all_pages(\"http://climate.weather.gc.ca/historical_data/search_historic_data_stations_e.html?searchType=stnProv&timeframe=1&lstProvince=&optLimit=yearRange&StartYear=1840&EndYear=2018&Year=2018&Month=4&Day=28&selRowPerPage=100\", count_recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406\n"
     ]
    }
   ],
   "source": [
    "summ = 0\n",
    "for element in result:\n",
    "    summ += int(element)\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
